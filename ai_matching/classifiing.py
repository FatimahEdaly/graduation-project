import mysql.connector
import re
import pandas as pd
from transformers import pipeline
from tqdm import tqdm

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
db_config = {
    'host': '127.0.0.1',
    'user': 'root',
    'password': '',
    'database': 'chef-link'
}

# --- 2. Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (Ù„Ù„Ù…ÙˆØ¯Ù„ ÙÙ‚Ø·) ---
def clean_for_ai(text):
    if pd.isna(text): return ""
    text = str(text)
    # Ø­Ø°Ù Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    text = re.sub(r'http\S+|www\S+|https\S+', '', text)
    # Ø­Ø°Ù Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ ÙˆØ§Ù„Ø±Ù…ÙˆØ² (ØªØ±Ùƒ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§ÙØ§Øª ÙÙ‚Ø·)
    text = re.sub(r'[^\u0600-\u06FF\s]', '', text)
    return " ".join(text.split())

# --- 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯Ù„ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ ---
print("â³ Ø¬Ø§Ø±Ù ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯Ù„ ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†Ø¸Ø§Ù…...")
classifier = pipeline("text-classification", model="job_post_classifier_model")

try:
    # Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ MySQL
    conn = mysql.connector.connect(**db_config)
    cursor = conn.cursor()

    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    df = pd.read_excel("posts.xlsx")
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    col = 'clean_post' if 'clean_post' in df.columns else df.columns[0]
    print(f"ğŸ” Ø³ÙŠØªÙ… Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯: '{col}'")
    print(f"ğŸš€ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© {len(df)} Ù…Ù†Ø´ÙˆØ±...")

    inserted_count = 0
    ignored_count = 0

    for index, row in tqdm(df.iterrows(), total=len(df)):
        original_post = str(row[col])
        
        # ØªÙ†Ø¸ÙŠÙ Ù…Ø¤Ù‚Øª Ù„Ù„Ù…ÙˆØ¯Ù„
        temp_text = clean_for_ai(original_post)
        if len(temp_text.split()) < 3: continue

        # Ø§Ù„ØªØµÙ†ÙŠÙ
        prediction = classifier(temp_text)[0]
        label = prediction['label']
        score = prediction['score']

        # --- 4. ÙÙ„ØªØ± Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø°ÙƒÙŠ ---
        # Ù„Ù† ÙŠÙ‚Ø¨Ù„ Ø¥Ù„Ø§ LABEL_1 (ÙˆØ¸ÙŠÙØ©) ÙˆØ¨Ø´Ø±Ø· Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø«Ù‚Ø© Ø£Ø¹Ù„Ù‰ Ù…Ù† 90%
        if label == 'LABEL_1' and score > 0.80:
            
            # Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±: Ø§Ù„ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù…Ù†Ø´ÙˆØ± ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ø§Ù‹
            cursor.execute("SELECT id FROM social_posts WHERE content = %s LIMIT 1", (original_post,))
            if cursor.fetchone(): continue

            # Ø§Ù„ØªØ®Ø²ÙŠÙ† ÙÙŠ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©
            sql = "INSERT INTO social_posts (content, platform, post_url) VALUES (%s, %s, %s)"
            val = (original_post, "System_AI", "N/A")
            cursor.execute(sql, val)
            inserted_count += 1
        else:
            ignored_count += 1

    # Ø­ÙØ¸ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
    conn.commit()
    
    print(f"\nâœ¨ Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
    print(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {inserted_count} Ø¥Ø¹Ù„Ø§Ù† ÙˆØ¸ÙŠÙÙŠ Ø­Ù‚ÙŠÙ‚ÙŠ.")
    print(f"ğŸš« ØªÙ… Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ {ignored_count} Ù…Ù†Ø´ÙˆØ± (Ø¥Ù…Ø§ Ù„ÙŠØ³Øª ÙˆØ¸Ø§Ø¦Ù Ø£Ùˆ Ø«Ù‚ØªÙ‡Ø§ Ø¶Ø¹ÙŠÙØ©).")

except Exception as e:
    print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
finally:
    if 'conn' in locals() and conn.is_connected():
        cursor.close()
        conn.close()