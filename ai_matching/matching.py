import mysql.connector
import re
from sentence_transformers import SentenceTransformer, util

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù…ÙˆØ¯ÙŠÙ„
db_config = {'host': '127.0.0.1', 'user': 'root', 'password': '', 'database': 'chef-link'}
model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')

def clean_text(text):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ ÙˆØ§Ù„Ø±Ù…ÙˆØ² Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª"""
    text = re.sub(r'[\d_]', ' ', text)
    text = re.sub(r'[^\u0600-\u06FFa-zA-Z\s]', ' ', text)
    return re.sub(r'\s+', ' ', text).strip()

def run_silent_matching():
    try:
        conn = mysql.connector.connect(**db_config)
        cursor = conn.cursor(dictionary=True)

        cursor.execute("SELECT id, content FROM social_posts")
        posts = cursor.fetchall()
        cursor.execute("SELECT national_id, skills FROM students")
        students = cursor.fetchall()

        all_skills = []
        for student in students:
            # Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù‡Ù†Ø§: Ø§Ù„ØªÙ‚Ø³ÙŠÙ… ÙŠØ¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„ÙÙˆØ§ØµÙ„ (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©)
            parts = re.split(r',|ØŒ', student['skills'])
            
            for s in parts:
                s_clean = clean_text(s.lower())
                if len(s_clean) > 2:
                    all_skills.append({
                        'sid': student['national_id'],
                        'skill_full': s_clean,
                        'skill_vec': model.encode(s_clean, convert_to_tensor=True)
                    })

        print("ğŸš€ Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª ÙˆØ§Ù„Ø±Ø¨Ø· Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ...")

        for post in posts:
            content = post['content'].lower()
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ø­Ø³Ø¨ Ø§Ù„Ø³Ø·Ø± Ø£Ùˆ Ø§Ù„Ù†Ù‚Ø·Ø© Ù„Ø¶Ù…Ø§Ù† Ø³ÙŠØ§Ù‚ Ù…Ù†Ø·Ù‚ÙŠ
            raw_chunks = re.split(r'\n|ØŒ|\.', content)
            
            best_match_for_student = {}

            for raw_chunk in raw_chunks:
                chunk = clean_text(raw_chunk)
                if len(chunk) < 3: continue

                chunk_vec = model.encode(chunk, convert_to_tensor=True)
                
                for skill in all_skills:
                    similarity = float(util.cos_sim(skill['skill_vec'], chunk_vec))

                    # Ø§Ù„Ø«Ø±ÙŠØ´ÙˆØ¯ Ø§Ù„Ù…Ø¹ØªÙ…Ø¯ 0.60 Ù„Ø¶Ù…Ø§Ù† Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
                    if similarity >= 0.60:
                        sid = skill['sid']
                        if sid not in best_match_for_student or similarity > best_match_for_student[sid]['score']:
                            best_match_for_student[sid] = {'score': similarity}

            # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª 
            if best_match_for_student:
                for sid, res in best_match_for_student.items():
                    cursor.execute("""
                        INSERT INTO chef_post_matches (graduate_id, post_id, similarity_score)
                        VALUES (%s, %s, %s)
                        ON DUPLICATE KEY UPDATE similarity_score = VALUES(similarity_score)
                    """, (sid, post['id'], res['score']))
                print(f"âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù†Ø´ÙˆØ± {post['id']} Ø¨Ù†Ø¬Ø§Ø­.")

        conn.commit()
        cursor.close()
        conn.close()
        print("\nâœ¨ Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ù‡Ù…Ø© ÙˆØ­ÙÙØ¸Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬.")

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: {e}")

if __name__ == "__main__":
    run_silent_matching()